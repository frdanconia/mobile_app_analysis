spatial_data <- merge(y = freq, x = map, by.y = "NUTS_ID", by.x = "NUTS_ID", sort = FALSE, all.x = F)
spatial_data <- merge(y = freq, x = map, by.y = "NUTS_ID", by.x = "NUTS_ID", sort = FALSE, all.x = F)
freq
freq
library(foreach)
library(dplyr)
library(tidyr)
library(mice)
library(vroom)
library(lubridate)
library(tidyverse)
library(lmtest)
library(rgdal)
library(sp)
library(spdep)
library(rgeos)
klienci <- vroom("data/klienci.csv")
session_geo <- vroom("data/session_geo.csv")
session_info <- vroom("data/session_info.csv")
klienci[, 1] <- c()
#1.	Ilu firma ma obecnie klientów i jaki procent z nich korzysta z usługi premium?
length(unique(klienci$klient_id))
length(unique(klienci$klient_id[klienci$czy_w_bazie_klientow == 1]))
klienci_w_bazie <- klienci[klienci$czy_w_bazie_klientow == 1, ]
sum(klienci_w_bazie$czy_kupil) / nrow(klienci_w_bazie)
sum(klienci[klienci$czy_w_bazie_klientow == 0, ]$czy_kupil) / nrow(klienci[klienci$czy_w_bazie_klientow == 0, ])
sum(klienci$czy_kupil) / nrow(klienci)
session <- merge(session_info, session_geo, by = "id_sesji")
eu_nuts <- readOGR(".", "NUTS_RG_01M_2013")
map <- subset(eu_nuts, STAT_LEVL_ == 3)
lon_lat <- data.frame(lon = session$lon, lat = session$lat)
coord2nuts <- function(lon_lat) {
coordinates(lon_lat) <- ~ lon + lat
proj4string(lon_lat) <- CRS("+init=epsg:4326")
map@proj4string <- lon_lat@proj4string
rt <- over(lon_lat, map)
return(rt)
}
session$nuts3 <- coord2nuts(lon_lat)$NUTS_ID
freq <- data.frame(table(session$nuts3))
freq <- freq[grepl("PL", freq$Var1), ]
map@data$NUTS_ID_char <- as.character(map@data$NUTS_ID)
map@data$country <- substr(map@data$NUTS_ID_char, 1, 2)
map <- map[map@data$country == "PL",]
spatial_data <-
merge(
y = freq,
x = map,
by.y = "NUTS_ID",
by.x = "NUTS_ID",
sort = FALSE,
all.x = F
)
colors <- brewer.pal(6, "Blues")
colnames(freq)
colnames(freq) <- ("NUTS_ID","FREQ")
colnames(freq) <- ("NUTS_ID","FREQ")
colnames(freq) <- c("NUTS_ID","FREQ")
map@data$NUTS_ID_char <- as.character(map@data$NUTS_ID)
map@data$country <- substr(map@data$NUTS_ID_char, 1, 2)
map <- map[map@data$country == "PL",]
spatial_data <-
merge(
y = freq,
x = map,
by.y = "NUTS_ID",
by.x = "NUTS_ID",
sort = FALSE,
all.x = F
)
colors <- brewer.pal(6, "Blues")
brks <- classIntervals(spatial_data$freq, 6)
colors <- brewer.pal(6, "Blues")
library(RColorBrewer)
klienci <- vroom("data/klienci.csv")
session_geo <- vroom("data/session_geo.csv")
session_info <- vroom("data/session_info.csv")
klienci[, 1] <- c()
#1.	Ilu firma ma obecnie klientów i jaki procent z nich korzysta z usługi premium?
length(unique(klienci$klient_id))
length(unique(klienci$klient_id[klienci$czy_w_bazie_klientow == 1]))
klienci_w_bazie <- klienci[klienci$czy_w_bazie_klientow == 1, ]
sum(klienci_w_bazie$czy_kupil) / nrow(klienci_w_bazie)
sum(klienci[klienci$czy_w_bazie_klientow == 0, ]$czy_kupil) / nrow(klienci[klienci$czy_w_bazie_klientow == 0, ])
sum(klienci$czy_kupil) / nrow(klienci)
session <- merge(session_info, session_geo, by = "id_sesji")
eu_nuts <- readOGR(".", "NUTS_RG_01M_2013")
map <- subset(eu_nuts, STAT_LEVL_ == 3)
lon_lat <- data.frame(lon = session$lon, lat = session$lat)
coord2nuts <- function(lon_lat) {
coordinates(lon_lat) <- ~ lon + lat
proj4string(lon_lat) <- CRS("+init=epsg:4326")
map@proj4string <- lon_lat@proj4string
rt <- over(lon_lat, map)
return(rt)
}
session$nuts3 <- coord2nuts(lon_lat)$NUTS_ID
freq <- data.frame(table(session$nuts3))
freq <- freq[grepl("PL", freq$Var1), ]
colnames(freq) <- c("NUTS_ID","FREQ")
map@data$NUTS_ID_char <- as.character(map@data$NUTS_ID)
map@data$country <- substr(map@data$NUTS_ID_char, 1, 2)
map <- map[map@data$country == "PL",]
spatial_data <-
merge(
y = freq,
x = map,
by.y = "NUTS_ID",
by.x = "NUTS_ID",
sort = FALSE,
all.x = F
)
colors <- brewer.pal(6, "Blues")
brks <- classIntervals(spatial_data$freq, 6)
library(classInt)
klienci <- vroom("data/klienci.csv")
session_geo <- vroom("data/session_geo.csv")
session_info <- vroom("data/session_info.csv")
klienci[, 1] <- c()
#1.	Ilu firma ma obecnie klientów i jaki procent z nich korzysta z usługi premium?
length(unique(klienci$klient_id))
length(unique(klienci$klient_id[klienci$czy_w_bazie_klientow == 1]))
klienci_w_bazie <- klienci[klienci$czy_w_bazie_klientow == 1, ]
sum(klienci_w_bazie$czy_kupil) / nrow(klienci_w_bazie)
sum(klienci[klienci$czy_w_bazie_klientow == 0, ]$czy_kupil) / nrow(klienci[klienci$czy_w_bazie_klientow == 0, ])
sum(klienci$czy_kupil) / nrow(klienci)
session <- merge(session_info, session_geo, by = "id_sesji")
eu_nuts <- readOGR(".", "NUTS_RG_01M_2013")
map <- subset(eu_nuts, STAT_LEVL_ == 3)
lon_lat <- data.frame(lon = session$lon, lat = session$lat)
coord2nuts <- function(lon_lat) {
coordinates(lon_lat) <- ~ lon + lat
proj4string(lon_lat) <- CRS("+init=epsg:4326")
map@proj4string <- lon_lat@proj4string
rt <- over(lon_lat, map)
return(rt)
}
session$nuts3 <- coord2nuts(lon_lat)$NUTS_ID
freq <- data.frame(table(session$nuts3))
freq <- freq[grepl("PL", freq$Var1), ]
colnames(freq) <- c("NUTS_ID","FREQ")
map@data$NUTS_ID_char <- as.character(map@data$NUTS_ID)
map@data$country <- substr(map@data$NUTS_ID_char, 1, 2)
map <- map[map@data$country == "PL",]
spatial_data <-
merge(
y = freq,
x = map,
by.y = "NUTS_ID",
by.x = "NUTS_ID",
sort = FALSE,
all.x = F
)
colors <- brewer.pal(6, "Blues")
brks <- classIntervals(spatial_data$freq, 6)
brks <- brks$brks
brks <- classIntervals(spatial_data$freq, 6)
brks <- classIntervals(spatial_data$FREQ, 6)
brks <- brks$brks
plot(spatial_data,
col = colors[findInterval(spatial_data$freq, brks, all.inside = TRUE)],
axes = F,
main = "Ilosc bezwzgledna przypadkow uzycia aplikacji")
brks <- brks$brks
plot(spatial_data,
col = colors[findInterval(spatial_data$FREQ, brks, all.inside = TRUE)],
axes = F,
main = "Ilosc bezwzgledna przypadkow uzycia aplikacji")
library(foreach)
library(dplyr)
library(tidyr)
library(mice)
library(vroom)
library(lubridate)
library(tidyverse)
library(lmtest)
library(rgdal)
library(sp)
library(spdep)
library(rgeos)
library(RColorBrewer)
library(classInt)
klienci <- vroom("data/klienci.csv")
session_geo <- vroom("data/session_geo.csv")
session_info <- vroom("data/session_info.csv")
klienci[, 1] <- c()
#1.	Ilu firma ma obecnie klientów i jaki procent z nich korzysta z usługi premium?
length(unique(klienci$klient_id))
length(unique(klienci$klient_id[klienci$czy_w_bazie_klientow == 1]))
klienci_w_bazie <- klienci[klienci$czy_w_bazie_klientow == 1, ]
sum(klienci_w_bazie$czy_kupil) / nrow(klienci_w_bazie)
sum(klienci[klienci$czy_w_bazie_klientow == 0, ]$czy_kupil) / nrow(klienci[klienci$czy_w_bazie_klientow == 0, ])
sum(klienci$czy_kupil) / nrow(klienci)
session <- merge(session_info, session_geo, by = "id_sesji")
eu_nuts <- readOGR(".", "NUTS_RG_01M_2013")
map <- subset(eu_nuts, STAT_LEVL_ == 3)
lon_lat <- data.frame(lon = session$lon, lat = session$lat)
coord2nuts <- function(lon_lat) {
coordinates(lon_lat) <- ~ lon + lat
proj4string(lon_lat) <- CRS("+init=epsg:4326")
map@proj4string <- lon_lat@proj4string
rt <- over(lon_lat, map)
return(rt)
}
session$nuts3 <- coord2nuts(lon_lat)$NUTS_ID
freq <- data.frame(table(session$nuts3))
freq <- freq[grepl("PL", freq$Var1), ]
colnames(freq) <- c("NUTS_ID","FREQ")
map@data$NUTS_ID_char <- as.character(map@data$NUTS_ID)
map@data$country <- substr(map@data$NUTS_ID_char, 1, 2)
map <- map[map@data$country == "PL",]
spatial_data <-
merge(
y = freq,
x = map,
by.y = "NUTS_ID",
by.x = "NUTS_ID",
sort = FALSE,
all.x = F
)
colors <- brewer.pal(6, "Blues")
brks <- classIntervals(spatial_data$FREQ, 6)
brks <- brks$brks
plot(spatial_data,
col = colors[findInterval(spatial_data$FREQ, brks, all.inside = TRUE)],
axes = F,
main = "Ilosc bezwzgledna przypadkow uzycia aplikacji")
barplot(table(klienci$plec), names.arg = c('Mezczyna', 'Kobieta'))
barplot(table(klienci$czy_samochod),
names.arg = c('Brak samochodu', 'Posiada samochod'))
barplot(table(klienci$czy_mieszkanie),
names.arg = c('Brak mieszkania', 'Posiada mieszkania'))
#Na fakt posiadania mieszkania, minimalnie wiecej osob posiada mieszkanie
mean(klienci$wiek[!is.na(klienci$wiek)])
median(klienci$wiek[!is.na(klienci$wiek)])
quantile(klienci$wiek, na.rm = TRUE)
#Ze wzgledu na wiek
#25% klientow jest w wieku w wieku od 18 do 25 lat
#25% klientow jest w wieku w wieku od 47 do 51 lat
#25% klientow jest w wieku w wieku od 51 do 55 lat
#25% klientow jest w wieku w wieku od 55 do 73 lat
#Aż 50% klientów jest w wieku od 47 do 55 lat
#Widac wiec ze bardzo wielu naszych klientow jest w poznych wieku srednim
#Srednia wynoi 51 lat i jest bardzo bliska mediany, nie ma wyraznej asymetrii rozkładu wieku klientow
densityplot(klienci$wiek)
#3.	Czy model płatny trafia zgodnie z założeniami do wykształconej grupy odbiorców?
table(klienci$wyksztalcenie[klienci$czy_kupil == 1])
mean(klienci$wiek[!is.na(klienci$wiek)])
median(klienci$wiek[!is.na(klienci$wiek)])
#4.	Czy zarobki użytkowników mają wpływ na częstotliwość korzystania z aplikacji i czas spędzany w apce?
salary <-
data.frame(klient_id = klienci$klient_id,
wynagrodzenie = klienci$wynagrodzenie)
for (i in 1:length(salary$klient_id)) {
salary$nsessions[i] <-
sum(session_info$klient_id == salary$klient_id[i])
}
poland_nuts3_population <- vroom("poland_nuts3_population.csv")
poland_nuts3_population <-
poland_nuts3_population[poland_nuts3_population$TIME == 2014, ]
poland_nuts3_population <- vroom("poland_nuts3_population.csv")
poland_nuts3_population <-
poland_nuts3_population[poland_nuts3_population$TIME == 2014, ]
poland_nuts3_population <-
poland_nuts3_population[poland_nuts3_population$TIME == 2013, ]
poland_nuts3_population <-
poland_nuts3_population[poland_nuts3_population$TIME == 2013, ]
poland_nuts3_population <- vroom("poland_nuts3_population.csv")
poland_nuts3_population
poland_nuts3_population$TIME
poland_nuts3_population$TIME == 2013
poland_nuts3_population <-
poland_nuts3_population[poland_nuts3_population$TIME == 2013, ]
poland_pop <-
data.frame(NUTS_ID = poland_nuts3_population$GEO, POP = poland_nuts3_population$Value)
freq2 <- freq %>% left_join(poland_pop, by = "NUTS_ID")
freq2
poland_nuts3_population <- vroom("poland_nuts3_population.csv")
poland_nuts3_population <-
poland_nuts3_population[poland_nuts3_population$TIME == 2013, ]
poland_pop <-
data.frame(NUTS_ID = poland_nuts3_population$GEO, POP = as.numeric(poland_nuts3_population$Value))
poland_nuts3_population <- vroom("poland_nuts3_population.csv")
poland_nuts3_population <-  poland_nuts3_population[poland_nuts3_population$TIME == 2013, ]
poland_pop <-
data.frame(NUTS_ID = poland_nuts3_population$GEO, POP = as.numeric(poland_nuts3_population$Value))
poland_pop <-
data.frame(NUTS_ID = poland_nuts3_population$GEO, POP = poland_nuts3_population$Value)
poland_pop$POP
as.numeric(poland_pop$POP)
gsup(",","",poland_pop$POP)
gsub(",","",poland_pop$POP)
as.numeric(gsub(",","",poland_pop$POP))
poland_pop
freq
poland_pop$POP <- as.numeric(gsub(",","",poland_pop$POP))
freq2 <- freq %>% left_join(poland_pop, by = "NUTS_ID")
freq2
freq <- freq %>% left_join(poland_pop, by = "NUTS_ID")
freq
freq$FREQ / freq$POP
freq$FREQ_PER_POP <- freq$FREQ / freq$POP
spatial_data <-
merge(
y = freq,
x = map,
by.y = "NUTS_ID",
by.x = "NUTS_ID",
sort = FALSE,
all.x = F
)
brks <- classIntervals(spatial_data$FREQ_PER_POP, 6)
brks <- brks$brks
colors <- brewer.pal(6, "Blues")
brks <- classIntervals(spatial_data$FREQ_PER_POP, 6)
brks <- brks$brks
plot(spatial_data,
col = colors[findInterval(spatial_data$FREQ_PER_POP, brks, all.inside = TRUE)],
axes = F,
main = "Ilosc przypadkow uzycia aplikacji wzgledem populacji regionu")
#8.	Czy klienci korzystają z aplikacji w jednym miejscu, czy może w większej liczbie miejsc? Jaki jest średni rozrzut odległości w wykorzystaniu aplikacji?
session$id_sesji
#8.	Czy klienci korzystają z aplikacji w jednym miejscu, czy może w większej liczbie miejsc? Jaki jest średni rozrzut odległości w wykorzystaniu aplikacji?
session$klient_id
#8.	Czy klienci korzystają z aplikacji w jednym miejscu, czy może w większej liczbie miejsc? Jaki jest średni rozrzut odległości w wykorzystaniu aplikacji?
session$klient_id[1]
library(dbscan)
library(foreach)
library(dplyr)
library(tidyr)
library(mice)
library(vroom)
library(lubridate)
library(tidyverse)
library(lmtest)
library(rgdal)
library(sp)
library(spdep)
library(rgeos)
library(RColorBrewer)
library(classInt)
library(dbscan)
library(geosphere)
source("PlotDbscanClustering.R")
klienci <- vroom("data/klienci.csv")
session_geo <- vroom("data/session_geo.csv")
session_info <- vroom("data/session_info.csv")
klienci[, 1] <- c()
#1.	Ilu firma ma obecnie klientów i jaki procent z nich korzysta z usługi premium?
length(unique(klienci$klient_id))
length(unique(klienci$klient_id[klienci$czy_w_bazie_klientow == 1]))
check_residental_coverage(session_geo$lat[1], session_geo$lon[1], 1000)
#devtools::install_github("hrbrmstr/overpass")
library(overpass)
library(overpass)
library(osmdata)
library(sp)
library(vroom)
session_geo <- vroom("data/session_geo.csv")
check_oo <- function(lat, lon, meter) {
lat1 <- as.numeric(lat - (180 / pi) * (meter / 6378137))
lon1 <-
as.numeric(lon - (180 / pi) * (meter / 6378137) / cos(lat1))
lat2 <- as.numeric(lat + (180 / pi) * (meter / 6378137))
lon2 <-
as.numeric(lon + (180 / pi) * (meter / 6378137) / cos(lat2))
bb <- c(lat1, lon1, lat2, lon2)
bbstring <- paste(bb, collapse = ",")
vv <- "residential"
q1 <-
paste0('  way["highway"="', vv, '"](', bbstring, ');', collapse = '\n')
qq <-
paste0('[out:xml][timeout:25]; \n( \n',
q1,
'); \nout body; \n>; \nout skel qt;')
oo <- overpass_query(qq)
return(oo)
}
check_residental_coverage <- function(lat, lon, meter) {
lat1 <- as.numeric(lat - (180 / pi) * (meter / 6378137))
lon1 <-
as.numeric(lon - (180 / pi) * (meter / 6378137) / cos(lat1))
lat2 <- as.numeric(lat + (180 / pi) * (meter / 6378137))
lon2 <-
as.numeric(lon + (180 / pi) * (meter / 6378137) / cos(lat2))
bb <- c(lat1, lon1, lat2, lon2)
bbstring <- paste(bb, collapse = ",")
vv <- "residential"
q1 <-
paste0('  way["highway"="', vv, '"](', bbstring, ');', collapse = '\n')
qq <-
paste0('[out:xml][timeout:25]; \n( \n',
q1,
'); \nout body; \n>; \nout skel qt;')
oo <- overpass_query(qq)
if (is.null(oo)) {
rt <- 0
} else {
rt <- (length(oo@data$highway) / meter) * 10
}
return(rt)
}
check_residental_coverage(session$lat[1], session$lon[1], 1000)
check_residental_coverage(session_geo$lat[1], session_geo$lon[1], 1000)
#devtools::install_github("hrbrmstr/overpass")
library(overpass)
library(osmdata)
library(sp)
library(vroom)
session_geo <- vroom("data/session_geo.csv")
check_oo <- function(lat, lon, meter) {
lat1 <- as.numeric(lat - (180 / pi) * (meter / 6378137))
lon1 <-
as.numeric(lon - (180 / pi) * (meter / 6378137) / cos(lat1))
lat2 <- as.numeric(lat + (180 / pi) * (meter / 6378137))
lon2 <-
as.numeric(lon + (180 / pi) * (meter / 6378137) / cos(lat2))
bb <- c(lat1, lon1, lat2, lon2)
bbstring <- paste(bb, collapse = ",")
vv <- "residential"
q1 <-
paste0('  way["highway"="', vv, '"](', bbstring, ');', collapse = '\n')
qq <-
paste0('[out:xml][timeout:25]; \n( \n',
q1,
'); \nout body; \n>; \nout skel qt;')
oo <- overpass_query(qq)
return(oo)
}
check_residental_coverage <- function(lat, lon, meter) {
lat1 <- as.numeric(lat - (180 / pi) * (meter / 6378137))
lon1 <-
as.numeric(lon - (180 / pi) * (meter / 6378137) / cos(lat1))
lat2 <- as.numeric(lat + (180 / pi) * (meter / 6378137))
lon2 <-
as.numeric(lon + (180 / pi) * (meter / 6378137) / cos(lat2))
bb <- c(lat1, lon1, lat2, lon2)
bbstring <- paste(bb, collapse = ",")
vv <- "residential"
q1 <-
paste0('  way["highway"="', vv, '"](', bbstring, ');', collapse = '\n')
qq <-
paste0('[out:xml][timeout:25]; \n( \n',
q1,
'); \nout body; \n>; \nout skel qt;')
oo <- overpass_query(qq)
if (is.null(oo)) {
rt <- 0
} else {
rt <- (length(oo@data$highway) / meter) * 10
}
return(rt)
}
check_residental_coverage(session_geo$lat[1], session_geo$lon[1], 1000)
#devtools::install_github("hrbrmstr/overpass")
library(overpass)
#devtools::install_github("hrbrmstr/overpass")
library(overpass)
#devtools::install_github("hrbrmstr/overpass")
library(overpass)
library(osmdata)
library(sp)
library(vroom)
session_geo <- vroom("data/session_geo.csv")
check_oo <- function(lat, lon, meter) {
lat1 <- as.numeric(lat - (180 / pi) * (meter / 6378137))
lon1 <-
as.numeric(lon - (180 / pi) * (meter / 6378137) / cos(lat1))
lat2 <- as.numeric(lat + (180 / pi) * (meter / 6378137))
lon2 <-
as.numeric(lon + (180 / pi) * (meter / 6378137) / cos(lat2))
bb <- c(lat1, lon1, lat2, lon2)
bbstring <- paste(bb, collapse = ",")
vv <- "residential"
q1 <-
paste0('  way["highway"="', vv, '"](', bbstring, ');', collapse = '\n')
qq <-
paste0('[out:xml][timeout:25]; \n( \n',
q1,
'); \nout body; \n>; \nout skel qt;')
oo <- overpass_query(qq)
return(oo)
}
check_residental_coverage <- function(lat, lon, meter) {
lat1 <- as.numeric(lat - (180 / pi) * (meter / 6378137))
lon1 <-
as.numeric(lon - (180 / pi) * (meter / 6378137) / cos(lat1))
lat2 <- as.numeric(lat + (180 / pi) * (meter / 6378137))
lon2 <-
as.numeric(lon + (180 / pi) * (meter / 6378137) / cos(lat2))
bb <- c(lat1, lon1, lat2, lon2)
bbstring <- paste(bb, collapse = ",")
vv <- "residential"
q1 <-
paste0('  way["highway"="', vv, '"](', bbstring, ');', collapse = '\n')
qq <-
paste0('[out:xml][timeout:25]; \n( \n',
q1,
'); \nout body; \n>; \nout skel qt;')
oo <- overpass_query(qq)
if (is.null(oo)) {
rt <- 0
} else {
rt <- (length(oo@data$highway) / meter) * 10
}
return(rt)
}
check_residental_coverage(session_geo$lat[1], session_geo$lon[1], 1000)
oo <- check_oo(session_geo$lat[3], session_geo$lon[3], 5000)
rm.packages("overpass")
remove.packages("overpass")
devtools::install_github("hrbrmstr/overpass")
