---
title: "Zadanie 3"
output:
  html_document:
    df_print: paged
---

<h3>Firma chce wdrożyć odpowiednią komunikację marketingową dla klientów, u których można stwierdzić szanse kupna produktu premium. Stwórz model klasyfikacyjny, którego celem jest przewidywanie którzy klienci mogą wykupić usługę premium. Jaka jest skuteczność takiego modelu? Jakie zmienne mają największy wpływ na decyzję o kupnie?</h3>

```{r}
suppressMessages(library(vroom))
suppressMessages(library(lubridate))
suppressMessages(library(xgboost))
suppressMessages(library(mice))
suppressMessages(library(xgboost))
suppressMessages(library(matrixStats))
suppressMessages(library(Matrix))
suppressMessages(library(tidyverse))
source("PlotVariableSparsity.R")
source("PlotVariableCardinality.R")
```

```{r}
data <- readRDS("klienci.RDS")
```

```{r}
md.pattern(data)
```
Imputacja brakow danych za pomoca predictive mean matching, to uniwersalna metoda a w sytuacji gdy mamy tak malo danych ciezko ocenic z jakim mechanizmem powstania brakow danych mamy do czynienia (MAR, MCAR, MNAR)

```{r}
imputed_data <- suppressMessages(mice(data, m=5, maxit = 50, method = 'pmm', seed = 500))
densityplot(imputed_data)

dt <- complete(imputed_data,3)
onehotmatrix <- model.matrix(object = czy_kupil ~ ., data = dt)
```

```{r}
PlotVariableSparsity(onehotmatrix)
```

Rzadkosc 0/1 jest akceptalna, wiekszym problemem rozrzedzenia zbioru moze byc ilosc feature'ow wzgledem ilosci obserwacji


```{r}
PlotVariableCardinality(dt,"czy_kupil")
```

Niektore kategorie maja bardzo niewiele obserwacji, nalezy pomyslec nad redukcja ilosci kategorii poprzez inne kodowanie zmiennych, z drugiej nalezy pamietac ze i tak mamy zaledwie 6000 obserwacji

```{r}
table(dt$avg_loc)
```

Bardzo duzo kategorii usrednionej lokalizacji wzgledem ilosci obserwacji im odpowiadajacych.

Nalezy dokonac konwersji kodow NUTS3 do wiekszych jednostek administracyjnych NUTS2

```{r}
for(i in 1:length(dt$avg_loc)){
  if(!is.na(dt$avg_loc[i])){ 
    if(nchar(dt$avg_loc[i]) == 5){
      dt$avg_loc[i] <- substr(dt$avg_loc[i],1,nchar(dt$avg_loc[i])-1)
    }
  }
}
```

Przypisanie brakow danych i zagranicy to oddzielnej kategorii, z uwagi na to, jak nieliczne to sa kategorie

```{r}
for(i in 1:length(dt$avg_loc)){
  if(is.na(dt$avg_loc[i])){ 
    dt$avg_loc[i] <- "OTHER"
  }
  
  if(!grepl("PL",dt$avg_loc[i])){
    dt$avg_loc[i] <- "OTHER"
  }

}
```

```{r}
table(dt$avg_loc)
```

```{r}
onehotmatrix <- model.matrix(object = czy_kupil ~ ., data = dt)
temp_df <- data.frame(onehotmatrix)
temp_df <- temp_df %>% left_join(dt)
```


```{r}
col.scale <- colMaxs(abs(onehotmatrix))
x.sc <- sweep(onehotmatrix, 2, col.scale, "/")

dtrain <- xgb.DMatrix(Matrix(x.sc, sparse = TRUE),
                      label = as.integer(temp_df$czy_kupil))
```

```{r}
xgb.params <- list(
  "booster" = "gbtree",
  "eta" = 0.05,
  "max_depth" = 4,
  "subsample" = 0.632,
  "colsample_bytree" = 0.4,
  "colsample_bylevel" = 0.6,
  "min_child_weight" = 1,
  "gamma" = 0,
  "lambda" = 0,
  "alpha" = 0,
  "objective" = "binary:logistic",
  "eval_metric" = "auc",
  "silent" = 1,
  "nthread" = 4,
  "num_parallel_tree" = 5
)
```

```{r}
set.seed(2020)
cv.out <-
  xgb.cv(
    params = xgb.params,
    data = dtrain,
    nrounds = 1.5e3,
    metrics = list('error'),
    nfold = 5,
    prediction = FALSE,
    verbose = TRUE,
    showsd = FALSE,
    print.every.n = 10,
    early.stop.round = 10,
    maximize = TRUE
  ) 

cv.out
```

0.723 auc na zbiorze testowym przy odchyleniu standardowym 0.032 przy 5 krotnej cross-validacji, przyzwoity wynik jak na tak maly zbior danych

Bez przekodowania zmiennej avg_loc model uzyskiwal maksymalne auc na zbiorze testowym na  poziomie 0.7, zatem zmiana ta poprawila model

```{r}
xgb.model <- xgb.train(data = dtrain,
                       params = xgb.params,
                       nrounds = 500)
```

```{r}
var.imp <- xgb.importance(colnames(x.sc), model = xgb.model) %>%
  mutate(Feature = gsub('[0-9]+', '', Feature)) %>%
  group_by(Feature) %>%
  summarise(Importance = quantile(Gain, 0.9)) %>%
  ungroup() %>%
  arrange(desc(Importance)) %>%
  mutate(Importance = round(100 * Importance / sum(Importance), 2))

var.imp
```

Na decyzje o kupnie najwiekszy wplyw ma 

a) wiek (wysoka istotnosc parametru bylo widac juz na etapie ekspolarcji zbioru danych)

b) wynagrodzenie

c) plec

d) statystyki dlugosc uzywania aplikacji

Przypuszczalnie czestotliowsc uzywania aplikacji ma wiekszy wplyw niż wynikaloby to z importance matrix z uwagi na to, ze jest ona reprezentowana przez rozne, silnie wspolniniowe zmienne (mialem kilka pomyslow w jaki sposob zakodowac czestotliwosc uzywania aplikacji). Xgboost jak wszystkie modele drzewiaste nie jest wrazliwy wspolliniowosc zmiennych pod katem jakosci tworzenia modelu, wspolliniowosc ma jednak wplyw na ksztalt importance matrix.